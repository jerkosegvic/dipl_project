{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerko/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import pandas\n",
    "import numpy\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_parquet('raw_data/RACE/validation-00000-of-00001.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>article</th>\n",
       "      <th>answer</th>\n",
       "      <th>question</th>\n",
       "      <th>options</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high5060.txt</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>C</td>\n",
       "      <td>What did the writer think of Timothy after lea...</td>\n",
       "      <td>[Timothy was very hardworking., Timothy was be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>high5060.txt</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>A</td>\n",
       "      <td>Which of the following statements best describ...</td>\n",
       "      <td>[Children should be allowed enough time to pla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>high5060.txt</td>\n",
       "      <td>I am a psychologist. I first met Timothy, a qu...</td>\n",
       "      <td>C</td>\n",
       "      <td>According to the passage, how long should a th...</td>\n",
       "      <td>[About ten minutes., No more than twenty minut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>high14410.txt</td>\n",
       "      <td>From self-driving cars to carebots (care+robot...</td>\n",
       "      <td>A</td>\n",
       "      <td>According to the report,   _  .</td>\n",
       "      <td>[people won't necessarily lose jobs, big compa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>high14410.txt</td>\n",
       "      <td>From self-driving cars to carebots (care+robot...</td>\n",
       "      <td>B</td>\n",
       "      <td>We can infer from the text that in the future ...</td>\n",
       "      <td>[people will face many difficulties, people wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4882</th>\n",
       "      <td>middle5525.txt</td>\n",
       "      <td>John and Jack met at the old bench every after...</td>\n",
       "      <td>B</td>\n",
       "      <td>John sat on the beach and probably waited for  _</td>\n",
       "      <td>[his mother, Jack, Steven, his uncle]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>middle5525.txt</td>\n",
       "      <td>John and Jack met at the old bench every after...</td>\n",
       "      <td>C</td>\n",
       "      <td>What is the best title for the passage?</td>\n",
       "      <td>[A birthday present, A football match, A home-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>middle7740.txt</td>\n",
       "      <td>Everyone has got two personalities --- the one...</td>\n",
       "      <td>A</td>\n",
       "      <td>You may find this passage in   _   .</td>\n",
       "      <td>[a science magazine, A shopping guide book, a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>middle7740.txt</td>\n",
       "      <td>Everyone has got two personalities --- the one...</td>\n",
       "      <td>B</td>\n",
       "      <td>Tina hardly tells her secrets to her friends ....</td>\n",
       "      <td>[curled up, on her stomach, on her back, on he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>middle7740.txt</td>\n",
       "      <td>Everyone has got two personalities --- the one...</td>\n",
       "      <td>C</td>\n",
       "      <td>What does the passage tell us ?</td>\n",
       "      <td>[Sleeping on you side is the best way of sleep...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4887 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          example_id                                            article  \\\n",
       "0       high5060.txt  I am a psychologist. I first met Timothy, a qu...   \n",
       "1       high5060.txt  I am a psychologist. I first met Timothy, a qu...   \n",
       "2       high5060.txt  I am a psychologist. I first met Timothy, a qu...   \n",
       "3      high14410.txt  From self-driving cars to carebots (care+robot...   \n",
       "4      high14410.txt  From self-driving cars to carebots (care+robot...   \n",
       "...              ...                                                ...   \n",
       "4882  middle5525.txt  John and Jack met at the old bench every after...   \n",
       "4883  middle5525.txt  John and Jack met at the old bench every after...   \n",
       "4884  middle7740.txt  Everyone has got two personalities --- the one...   \n",
       "4885  middle7740.txt  Everyone has got two personalities --- the one...   \n",
       "4886  middle7740.txt  Everyone has got two personalities --- the one...   \n",
       "\n",
       "     answer                                           question  \\\n",
       "0         C  What did the writer think of Timothy after lea...   \n",
       "1         A  Which of the following statements best describ...   \n",
       "2         C  According to the passage, how long should a th...   \n",
       "3         A                    According to the report,   _  .   \n",
       "4         B  We can infer from the text that in the future ...   \n",
       "...     ...                                                ...   \n",
       "4882      B   John sat on the beach and probably waited for  _   \n",
       "4883      C            What is the best title for the passage?   \n",
       "4884      A               You may find this passage in   _   .   \n",
       "4885      B  Tina hardly tells her secrets to her friends ....   \n",
       "4886      C                    What does the passage tell us ?   \n",
       "\n",
       "                                                options  \n",
       "0     [Timothy was very hardworking., Timothy was be...  \n",
       "1     [Children should be allowed enough time to pla...  \n",
       "2     [About ten minutes., No more than twenty minut...  \n",
       "3     [people won't necessarily lose jobs, big compa...  \n",
       "4     [people will face many difficulties, people wi...  \n",
       "...                                                 ...  \n",
       "4882              [his mother, Jack, Steven, his uncle]  \n",
       "4883  [A birthday present, A football match, A home-...  \n",
       "4884  [a science magazine, A shopping guide book, a ...  \n",
       "4885  [curled up, on her stomach, on her back, on he...  \n",
       "4886  [Sleeping on you side is the best way of sleep...  \n",
       "\n",
       "[4887 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With a \"Fast Lane\" card, visitors can   _  .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['question'][365]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data/ReCoRD/train.json') as f:\n",
    "    record_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_dataset = pandas.DataFrame(record_dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>passage</th>\n",
       "      <th>qas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>536e2fdfb3c986efa15da314b0df2d2d218cf693</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'The harrowing stories of women and c...</td>\n",
       "      <td>[{'id': '536e2fdfb3c986efa15da314b0df2d2d218cf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f15689cd256daa03fcfd8c357f1376a8a7017b64</td>\n",
       "      <td>CNN</td>\n",
       "      <td>{'text': 'Caracas, Venezuela (CNN) -- It's bee...</td>\n",
       "      <td>[{'id': 'f15689cd256daa03fcfd8c357f1376a8a7017...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bd4f4fd84a92411a7c03fe80fa2e84270ac51ac3</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'U.S. Secretary of State Henry Kissin...</td>\n",
       "      <td>[{'id': 'bd4f4fd84a92411a7c03fe80fa2e84270ac51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16f4d0c2b42cfd57557d1aaf398110ebf519874f</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'A Peruvian tribe once revered by the...</td>\n",
       "      <td>[{'id': '16f4d0c2b42cfd57557d1aaf398110ebf5198...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a204b0da2b9a5267a0527632ab8d5691b2c412de</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'For everyone who has ever thought ab...</td>\n",
       "      <td>[{'id': 'a204b0da2b9a5267a0527632ab8d5691b2c41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65704</th>\n",
       "      <td>6079a996b955d3130ad59c37b57d9958e0539b83</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'Liverpool are ready to revive their ...</td>\n",
       "      <td>[{'id': '6079a996b955d3130ad59c37b57d9958e0539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65705</th>\n",
       "      <td>4e466fabc27adf6cb2180c8441f9b0d5266062ba</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'A Russian tourist has been hospitali...</td>\n",
       "      <td>[{'id': '4e466fabc27adf6cb2180c8441f9b0d526606...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65706</th>\n",
       "      <td>cc54a42ae756fa5bddda37e91948149793bd072b</td>\n",
       "      <td>CNN</td>\n",
       "      <td>{'text': 'Editor's note: Ilya Shapiro is a sen...</td>\n",
       "      <td>[{'id': 'cc54a42ae756fa5bddda37e91948149793bd0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65707</th>\n",
       "      <td>5c6f7eec2a86ccd30d412c24f90f4c1e91aa607b</td>\n",
       "      <td>CNN</td>\n",
       "      <td>{'text': '(CNN) -- Newt Gingrich quit the pres...</td>\n",
       "      <td>[{'id': '5c6f7eec2a86ccd30d412c24f90f4c1e91aa6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65708</th>\n",
       "      <td>c12e2c7c36bd87b7b34dead0a18231431f7fcdaa</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'By Kieran Gill Anton Ferdinand has s...</td>\n",
       "      <td>[{'id': 'c12e2c7c36bd87b7b34dead0a18231431f7fc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65709 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id      source  \\\n",
       "0      536e2fdfb3c986efa15da314b0df2d2d218cf693  Daily mail   \n",
       "1      f15689cd256daa03fcfd8c357f1376a8a7017b64         CNN   \n",
       "2      bd4f4fd84a92411a7c03fe80fa2e84270ac51ac3  Daily mail   \n",
       "3      16f4d0c2b42cfd57557d1aaf398110ebf519874f  Daily mail   \n",
       "4      a204b0da2b9a5267a0527632ab8d5691b2c412de  Daily mail   \n",
       "...                                         ...         ...   \n",
       "65704  6079a996b955d3130ad59c37b57d9958e0539b83  Daily mail   \n",
       "65705  4e466fabc27adf6cb2180c8441f9b0d5266062ba  Daily mail   \n",
       "65706  cc54a42ae756fa5bddda37e91948149793bd072b         CNN   \n",
       "65707  5c6f7eec2a86ccd30d412c24f90f4c1e91aa607b         CNN   \n",
       "65708  c12e2c7c36bd87b7b34dead0a18231431f7fcdaa  Daily mail   \n",
       "\n",
       "                                                 passage  \\\n",
       "0      {'text': 'The harrowing stories of women and c...   \n",
       "1      {'text': 'Caracas, Venezuela (CNN) -- It's bee...   \n",
       "2      {'text': 'U.S. Secretary of State Henry Kissin...   \n",
       "3      {'text': 'A Peruvian tribe once revered by the...   \n",
       "4      {'text': 'For everyone who has ever thought ab...   \n",
       "...                                                  ...   \n",
       "65704  {'text': 'Liverpool are ready to revive their ...   \n",
       "65705  {'text': 'A Russian tourist has been hospitali...   \n",
       "65706  {'text': 'Editor's note: Ilya Shapiro is a sen...   \n",
       "65707  {'text': '(CNN) -- Newt Gingrich quit the pres...   \n",
       "65708  {'text': 'By Kieran Gill Anton Ferdinand has s...   \n",
       "\n",
       "                                                     qas  \n",
       "0      [{'id': '536e2fdfb3c986efa15da314b0df2d2d218cf...  \n",
       "1      [{'id': 'f15689cd256daa03fcfd8c357f1376a8a7017...  \n",
       "2      [{'id': 'bd4f4fd84a92411a7c03fe80fa2e84270ac51...  \n",
       "3      [{'id': '16f4d0c2b42cfd57557d1aaf398110ebf5198...  \n",
       "4      [{'id': 'a204b0da2b9a5267a0527632ab8d5691b2c41...  \n",
       "...                                                  ...  \n",
       "65704  [{'id': '6079a996b955d3130ad59c37b57d9958e0539...  \n",
       "65705  [{'id': '4e466fabc27adf6cb2180c8441f9b0d526606...  \n",
       "65706  [{'id': 'cc54a42ae756fa5bddda37e91948149793bd0...  \n",
       "65707  [{'id': '5c6f7eec2a86ccd30d412c24f90f4c1e91aa6...  \n",
       "65708  [{'id': 'c12e2c7c36bd87b7b34dead0a18231431f7fc...  \n",
       "\n",
       "[65709 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>passage</th>\n",
       "      <th>qas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65704</th>\n",
       "      <td>6079a996b955d3130ad59c37b57d9958e0539b83</td>\n",
       "      <td>Daily mail</td>\n",
       "      <td>{'text': 'Liverpool are ready to revive their ...</td>\n",
       "      <td>[{'id': '6079a996b955d3130ad59c37b57d9958e0539...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             id      source  \\\n",
       "65704  6079a996b955d3130ad59c37b57d9958e0539b83  Daily mail   \n",
       "\n",
       "                                                 passage  \\\n",
       "65704  {'text': 'Liverpool are ready to revive their ...   \n",
       "\n",
       "                                                     qas  \n",
       "65704  [{'id': '6079a996b955d3130ad59c37b57d9958e0539...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_rows = record_dataset[record_dataset['id'] == '6079a996b955d3130ad59c37b57d9958e0539b83']\n",
    "filtered_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '33ae938f21c5e4118caa4109967e177e540f1c37-2db27135766475e5e4554128801bb5fab53e80ce-72',\n",
       "  'query': \"But here's what the three main players -- the United States, Russia and @placeholder -- are really thinking.\",\n",
       "  'answers': [{'start': 342, 'end': 347, 'text': 'Turkey'},\n",
       "   {'start': 651, 'end': 655, 'text': 'Turks'},\n",
       "   {'start': 701, 'end': 707, 'text': 'Turkish'}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_dataset['qas'][74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data/multirc-v2/splitv2/train_456-fixedIds.json') as f:\n",
    "    rc_dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_dataset = pandas.DataFrame(rc_dataset['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paragraph</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;Animated history of t...</td>\n",
       "      <td>Society_Law_and_Justice/masc-A_defense_of_Mich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;Before the mysterious...</td>\n",
       "      <td>News/CNN/cnn-3b372dbbdea7cabac969352b8b3169a0e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;Hotel California My f...</td>\n",
       "      <td>Fiction-stories-masc-hotel-California-1.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;Elaan is a declaratio...</td>\n",
       "      <td>wikiMovieSummaries-27380172.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;Not until 1998 did al...</td>\n",
       "      <td>Sept11-reports/oanc-chapter-2-5.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;How would the univers...</td>\n",
       "      <td>Science-textbook/science-g3-31.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;Once upon a time ther...</td>\n",
       "      <td>Fiction/mctest-mc160.dev.5-0.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;In her storage room-t...</td>\n",
       "      <td>Society_Law_and_Justice/oanc-Crains_New_York_B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;A West Tennessee nonp...</td>\n",
       "      <td>Society_Law_and_Justice/oanc-fight_domestic_ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>{'text': '&lt;b&gt;Sent 1: &lt;/b&gt;U.S. Secretary of Sta...</td>\n",
       "      <td>News/NYT/masc-20020731-nyt-4.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             paragraph  \\\n",
       "0    {'text': '<b>Sent 1: </b>Animated history of t...   \n",
       "1    {'text': '<b>Sent 1: </b>Before the mysterious...   \n",
       "2    {'text': '<b>Sent 1: </b>Hotel California My f...   \n",
       "3    {'text': '<b>Sent 1: </b>Elaan is a declaratio...   \n",
       "4    {'text': '<b>Sent 1: </b>Not until 1998 did al...   \n",
       "..                                                 ...   \n",
       "451  {'text': '<b>Sent 1: </b>How would the univers...   \n",
       "452  {'text': '<b>Sent 1: </b>Once upon a time ther...   \n",
       "453  {'text': '<b>Sent 1: </b>In her storage room-t...   \n",
       "454  {'text': '<b>Sent 1: </b>A West Tennessee nonp...   \n",
       "455  {'text': '<b>Sent 1: </b>U.S. Secretary of Sta...   \n",
       "\n",
       "                                                    id  \n",
       "0    Society_Law_and_Justice/masc-A_defense_of_Mich...  \n",
       "1    News/CNN/cnn-3b372dbbdea7cabac969352b8b3169a0e...  \n",
       "2          Fiction-stories-masc-hotel-California-1.txt  \n",
       "3                      wikiMovieSummaries-27380172.txt  \n",
       "4                  Sept11-reports/oanc-chapter-2-5.txt  \n",
       "..                                                 ...  \n",
       "451                 Science-textbook/science-g3-31.txt  \n",
       "452                   Fiction/mctest-mc160.dev.5-0.txt  \n",
       "453  Society_Law_and_Justice/oanc-Crains_New_York_B...  \n",
       "454  Society_Law_and_Justice/oanc-fight_domestic_ab...  \n",
       "455                   News/NYT/masc-20020731-nyt-4.txt  \n",
       "\n",
       "[456 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'questions'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_dataset['paragraph'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: Animated history of the US.\n",
      "Sentence 2: Of course the cartoon is highly oversimplified, and most critics consider it one of the weakest parts of the film.\n",
      "Sentence 3: But it makes a valid claim which you ignore entirely: That the strategy to promote \"gun rights\" for white people and to outlaw gun possession by black people was a way to uphold racism without letting an openly terrorist organization like the KKK flourish.\n",
      "Sentence 4: Did the 19th century NRA in the southern states promote gun rights for black people?\n",
      "Sentence 5: I highly doubt it.\n",
      "Sentence 6: But if they didn't, one of their functions was to continue the racism of the KKK.\n",
      "Sentence 7: This is the key message of this part of the animation, which is again being ignored by its critics.\n",
      "Sentence 8: Buell shooting in Flint.\n",
      "Sentence 9: You write: \"Fact: The little boy was the class thug, already suspended from school for stabbing another kid with a pencil, and had fought with Kayla the day before\".\n",
      "Sentence 10: This characterization of a six-year-old as a pencil-stabbing thug is exactly the kind of hysteria that Moore's film warns against.\n",
      "Sentence 11: It is the typical right-wing reaction which looks for simple answers that do not contradict the Republican mindset.\n",
      "Sentence 12: The kid was a little bastard, and the parents were involved in drugs -- case closed.\n",
      "Sentence 13: But why do people deal with drugs?\n",
      "Sentence 14: Because it's so much fun to do so?\n",
      "Sentence 15: It is by now well documented that the CIA tolerated crack sales in US cities to fund the operation of South American \"contras\" It is equally well known that the so-called \"war on drugs\" begun under the Nixon administration is a failure which has cost hundreds of billions and made America the world leader in prison population (both in relative and absolute numbers).\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = rc_dataset['paragraph'][0]['text']\n",
    "\n",
    "pattern = r\"<b>Sent \\d+: </b>(.*?)<br>\"\n",
    "sentences = re.findall(pattern, text)\n",
    "\n",
    "# Print the sentences\n",
    "for i, sentence in enumerate(sentences, 1):\n",
    "    print(f\"Sentence {i}: {sentence}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'After what successfully won battle was Philip named \"Hegemon\"',\n",
       " 'sentences_used': [9, 10, 1, 8],\n",
       " 'answers': [{'text': 'Modern scholars', 'isAnswer': False, 'scores': {}},\n",
       "  {'text': 'The battle of Sparta', 'isAnswer': False, 'scores': {}},\n",
       "  {'text': 'Battle of Chaeronea', 'isAnswer': True, 'scores': {}}],\n",
       " 'idx': '5',\n",
       " 'multisent': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc_dataset['paragraph'][6]['questions'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('raw_data/BoolQ/train.jsonl') as f:\n",
    "    boolq_dataset = f.readlines()\n",
    "\n",
    "boolq_dataset = pandas.DataFrame([json.loads(x) for x in boolq_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>title</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>do iran and afghanistan speak the same language</td>\n",
       "      <td>Persian language</td>\n",
       "      <td>True</td>\n",
       "      <td>Persian (/ˈpɜːrʒən, -ʃən/), also known by its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>do good samaritan laws protect those who help ...</td>\n",
       "      <td>Good Samaritan law</td>\n",
       "      <td>True</td>\n",
       "      <td>Good Samaritan laws offer legal protection to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is windows movie maker part of windows essentials</td>\n",
       "      <td>Windows Movie Maker</td>\n",
       "      <td>True</td>\n",
       "      <td>Windows Movie Maker (formerly known as Windows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>is confectionary sugar the same as powdered sugar</td>\n",
       "      <td>Powdered sugar</td>\n",
       "      <td>True</td>\n",
       "      <td>Powdered sugar, also called confectioners' sug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>is elder scrolls online the same as skyrim</td>\n",
       "      <td>The Elder Scrolls Online</td>\n",
       "      <td>False</td>\n",
       "      <td>As with other games in The Elder Scrolls serie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9422</th>\n",
       "      <td>is a us district court a federal court</td>\n",
       "      <td>United States district court</td>\n",
       "      <td>True</td>\n",
       "      <td>The United States district courts are the gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9423</th>\n",
       "      <td>can a tenant get a restraining order against a...</td>\n",
       "      <td>Landlord harassment</td>\n",
       "      <td>True</td>\n",
       "      <td>If a landlord is found to be retaliating, he o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9424</th>\n",
       "      <td>is the golden state warriors in the playoffs</td>\n",
       "      <td>Golden State Warriors</td>\n",
       "      <td>True</td>\n",
       "      <td>The Warriors went into the 2018 playoffs as th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9425</th>\n",
       "      <td>downton abbey will there be a season 7</td>\n",
       "      <td>List of Downton Abbey episodes</td>\n",
       "      <td>False</td>\n",
       "      <td>Downton Abbey is a British period drama televi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9426</th>\n",
       "      <td>is margin of error the same as confidence inte...</td>\n",
       "      <td>Margin of error</td>\n",
       "      <td>False</td>\n",
       "      <td>The margin of error is usually defined as the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9427 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "0       do iran and afghanistan speak the same language   \n",
       "1     do good samaritan laws protect those who help ...   \n",
       "2     is windows movie maker part of windows essentials   \n",
       "3     is confectionary sugar the same as powdered sugar   \n",
       "4            is elder scrolls online the same as skyrim   \n",
       "...                                                 ...   \n",
       "9422             is a us district court a federal court   \n",
       "9423  can a tenant get a restraining order against a...   \n",
       "9424       is the golden state warriors in the playoffs   \n",
       "9425             downton abbey will there be a season 7   \n",
       "9426  is margin of error the same as confidence inte...   \n",
       "\n",
       "                               title  answer  \\\n",
       "0                   Persian language    True   \n",
       "1                 Good Samaritan law    True   \n",
       "2                Windows Movie Maker    True   \n",
       "3                     Powdered sugar    True   \n",
       "4           The Elder Scrolls Online   False   \n",
       "...                              ...     ...   \n",
       "9422    United States district court    True   \n",
       "9423             Landlord harassment    True   \n",
       "9424           Golden State Warriors    True   \n",
       "9425  List of Downton Abbey episodes   False   \n",
       "9426                 Margin of error   False   \n",
       "\n",
       "                                                passage  \n",
       "0     Persian (/ˈpɜːrʒən, -ʃən/), also known by its ...  \n",
       "1     Good Samaritan laws offer legal protection to ...  \n",
       "2     Windows Movie Maker (formerly known as Windows...  \n",
       "3     Powdered sugar, also called confectioners' sug...  \n",
       "4     As with other games in The Elder Scrolls serie...  \n",
       "...                                                 ...  \n",
       "9422  The United States district courts are the gene...  \n",
       "9423  If a landlord is found to be retaliating, he o...  \n",
       "9424  The Warriors went into the 2018 playoffs as th...  \n",
       "9425  Downton Abbey is a British period drama televi...  \n",
       "9426  The margin of error is usually defined as the ...  \n",
       "\n",
       "[9427 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq_dataset['answer'][42] == False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (908 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from datasets import Boolq_dataset\n",
    "from dataset_loaders import load_boolq\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "boolq_dataset = load_boolq(\"raw_data/BoolQ/train.jsonl\", BertTokenizer.from_pretrained('bert-base-uncased'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1996, 28833, 15790, 13170,  1006, 26632, 15721,  7274,  8915,  7382,\n",
       "           2378, 18009,  2072,  1007,  2003,  1037,  2427,  1997, 13170,  1999,\n",
       "           1996,  2155, 18178,  2135, 13626,  6096,  1010,  3128,  2000, 12573,\n",
       "          10746,  1999,  1996,  2142,  2163,  1012,  1049,  1012,  8915,  7382,\n",
       "           2378, 18009,  2072,  2003,  2028,  1997,  1996, 26858, 12573, 16489,\n",
       "           1999,  1996,  2088,  1012,  2009,  2003,  2411,  3378,  2007,  1010,\n",
       "           2021,  2025,  4876,  3141,  2000,  1010,  1996,  2691, 15790, 13170,\n",
       "           1010,  2029,  2003,  1999,  1996,  3562, 18178,  2135,  7265,  1012,\n",
       "           1996,  3563, 19626,  8915,  7382,  2378, 18009,  2072,  2003,  1999,\n",
       "           3932,  1997,  3803,  9201, 10727, 24873, 16118, 11057,  2094,  6213,\n",
       "           8915,  7382,  2378,  3600,  1012,  2003,  2045,  2107,  2518,  2004,\n",
       "           2019, 28833, 15790, 13170,  1029,  2748,  1012]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, 2748, 1012]),\n",
       " tensor([[ 1996, 28833, 15790, 13170,  1006, 26632, 15721,  7274,  8915,  7382,\n",
       "           2378, 18009,  2072,  1007,  2003,  1037,  2427,  1997, 13170,  1999,\n",
       "           1996,  2155, 18178,  2135, 13626,  6096,  1010,  3128,  2000, 12573,\n",
       "          10746,  1999,  1996,  2142,  2163,  1012,  1049,  1012,  8915,  7382,\n",
       "           2378, 18009,  2072,  2003,  2028,  1997,  1996, 26858, 12573, 16489,\n",
       "           1999,  1996,  2088,  1012,  2009,  2003,  2411,  3378,  2007,  1010,\n",
       "           2021,  2025,  4876,  3141,  2000,  1010,  1996,  2691, 15790, 13170,\n",
       "           1010,  2029,  2003,  1999,  1996,  3562, 18178,  2135,  7265,  1012,\n",
       "           1996,  3563, 19626,  8915,  7382,  2378, 18009,  2072,  2003,  1999,\n",
       "           3932,  1997,  3803,  9201, 10727, 24873, 16118, 11057,  2094,  6213,\n",
       "           8915,  7382,  2378,  3600,  1012,  2003,  2045,  2107,  2518,  2004,\n",
       "           2019, 28833, 15790, 13170,  1029,  2053,  1012]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, 2053, 1012]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolq_dataset[435]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from datasets import MultiRC_dataset\n",
    "from dataset_loaders import load_multirc\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "multirc_dataset = load_multirc(\"raw_data/multirc-v2/splitv2/train_456-fixedIds.json\", BertTokenizer.from_pretrained('bert-base-uncased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4918, 21442, 22231,  2638,  2018,  2053,  7669,  1999, 12329,  2010,\n",
       "           2713,  2043,  6262,  2234,  2006,  4611,  2012,  2416,  1051,  1005,\n",
       "           5119,  1012,  2002,  2170,  2039,  1037,  9298,  1998,  2253,  2012,\n",
       "           2320,  2000,  2010,  4734,  2012,  1996,  7987,  5602, 23567,  2063,\n",
       "           1025,  1998,  9666, 15010,  2628,  2032,  1012,  2096,  2002, 15105,\n",
       "           2010,  4377,  1011,  5435,  1010,  2165,  1037,  7198,  1998,  2123,\n",
       "           7228,  2010,  3788,  4848, 21442, 22231,  2638,  2001,  1999,  1037,\n",
       "           2829,  2817,  1012,  2847,  3283,  8227,  2018,  2042,  9689,  5565,\n",
       "           2012,  1996,  2264,  4589,  2160,  1998,  2872,  1999,  1996,  2729,\n",
       "           1997,  2214, 10602,  8292, 29346,  1010,  2040,  2052,  3457,  2014,\n",
       "           2066,  2019, 13958,  2890,  1012,  2045,  2001,  2053,  6234,  2342,\n",
       "           1997,  2010, 24748,  5582,  2044,  2014,  1010,  1998,  2010,  6545,\n",
       "           1998,  1996,  5456,  1997,  2431,  2010,  5436,  2018,  5667, 12491,\n",
       "           2032,  1012,  2023,  2402,  2158,  2001,  2053, 23131,  1999, 20014,\n",
       "          27611,  1010,  4496,  2130,  1999,  4126,  1012,  9177,  2013,  2010,\n",
       "           2219,  3233,  1011,  2391,  2002,  3651,  2008,  1996,  2814,  1997,\n",
       "           8227,  2020,  2011,  2023,  2051,  2478,  2296, 23855,  2000, 12453,\n",
       "           2014,  1012,  2027,  2052,  2025,  9510,  1999,  2023,  1010,  2002,\n",
       "           2001,  3893,  1012,  2010,  5436,  2018,  2042,  2061,  8740,  2850,\n",
       "          18436,  1998,  2035, 18856,  7974,  2015,  2061, 12266,  2135,  3908,\n",
       "           2030,  3139,  2039,  2008,  1996,  2087,  8066,  3993,  6317,  1010,\n",
       "           4209,  2002,  2018, 20361,  1996,  2611,  1025,  2052,  2022,  3294,\n",
       "          29088,  1999,  2019,  3535,  2000,  2424,  2014,  1012,  2054,  2785,\n",
       "           1997,  7022,  2038,  6027,  2363,  7175,  2049,  8304,  1997,  1996,\n",
       "          13406,  1997,  6027,  7608,  3462, 16444,  1029,  1029,  2009,  8440,\n",
       "           1005,  1056,  6003,  2007,  2200,  2204,  7022]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, 2009, 8440, 1005, 1056,\n",
       "         6003, 2007, 2200, 2204, 7022]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multirc_dataset[56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Does the author claim the animated films message is that the NRA upholds racism?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multirc_dataset.question_answer_objs[0].question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animated history of the US.',\n",
       " 'Of course the cartoon is highly oversimplified, and most critics consider it one of the weakest parts of the film.',\n",
       " 'But it makes a valid claim which you ignore entirely: That the strategy to promote \"gun rights\" for white people and to outlaw gun possession by black people was a way to uphold racism without letting an openly terrorist organization like the KKK flourish.',\n",
       " 'Did the 19th century NRA in the southern states promote gun rights for black people?',\n",
       " 'I highly doubt it.',\n",
       " \"But if they didn't, one of their functions was to continue the racism of the KKK.\",\n",
       " 'This is the key message of this part of the animation, which is again being ignored by its critics.',\n",
       " 'Buell shooting in Flint.',\n",
       " 'You write: \"Fact: The little boy was the class thug, already suspended from school for stabbing another kid with a pencil, and had fought with Kayla the day before\".',\n",
       " \"This characterization of a six-year-old as a pencil-stabbing thug is exactly the kind of hysteria that Moore's film warns against.\",\n",
       " 'It is the typical right-wing reaction which looks for simple answers that do not contradict the Republican mindset.',\n",
       " 'The kid was a little bastard, and the parents were involved in drugs -- case closed.',\n",
       " 'But why do people deal with drugs?',\n",
       " \"Because it's so much fun to do so?\",\n",
       " 'It is by now well documented that the CIA tolerated crack sales in US cities to fund the operation of South American \"contras\" It is equally well known that the so-called \"war on drugs\" begun under the Nixon administration is a failure which has cost hundreds of billions and made America the world leader in prison population (both in relative and absolute numbers).']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multirc_dataset.passages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? it hasn't emerged with very good grades [SEP]\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenizer.decode([  1029, 2009, 8440, 1005,\n",
    "         1056, 6003, 2007, 2200, 2204, 7022,  102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28352, 1038, 2721, 1038, 2721]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = \"bal bla    bla _ bla\"\n",
    "tokenizer.encode(a[:a.index(\"_\")], add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] bal bla bla _ bla [SEP]'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(  [101, 28352, 1038, 2721, 1038, 2721, 1035, 1038, 2721, 102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (533 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from datasets import ReCoRD_dataset\n",
    "from dataset_loaders import load_race\n",
    "\n",
    "race_dataset = load_race(\"raw_data/RACE/validation-00000-of-00001.parquet\", BertTokenizer.from_pretrained('bert-base-uncased'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3679\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-100, -100, -100, -100, -100, -100, 6848, 1996, 4784, 2007, 2500, -100,\n",
       "        -100, -100, -100, -100, -100, -100, -100, -100])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.randint(4000)\n",
    "print(a)\n",
    "race_dataset[a][2][-20:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 2071,  2017,  2022,  1037, 11067,  2066, 15313,  1029,  1037, 11067,\n",
       "           3791,  2000,  4553,  1998,  2228,  1012,  3752,  2003,  1037,  2204,\n",
       "           2801,  1010,  2021,  2009,  2003,  2025,  2438,  1012, 15313,  1005,\n",
       "           1055,  6040,  2003,  2000,  2224,  2115,  4167,  2062,  1012,  2182,\n",
       "           2024,  2070, 10247,  1024,  1048,  3198,  1012,  2043,  2017,  2298,\n",
       "           2012,  2047,  2477,  1010,  3198,  2339,  2027,  2024,  2047,  2030,\n",
       "           2367,  1012,  3198,  2062,  3980,  1012,  3198,  4426,  1998,  2500,\n",
       "           1012,  2562,  3241,  2127,  2017,  2424,  1996,  6998,  1012,  1048,\n",
       "           4009,  1012, 15313,  2245,  1999,  4620,  1012,  2823,  1010,  2009,\n",
       "           7126,  2000,  4009,  3471,  1998,  4784,  1012,  1048,  3191,  1012,\n",
       "           3046,  2000,  3191,  2047,  2477,  1012,  3191,  2808,  2013,  2367,\n",
       "           3033,  1997,  1996,  3075,  1012,  2044,  2017,  3191,  1010,  2228,\n",
       "           2055,  1996,  4784,  2017,  2031,  4342,  1012,  2024,  2027,  2367,\n",
       "           2013,  2054,  2017,  2245,  1029,  1048,  9483,  1012,  2116,  4784,\n",
       "           2272,  2043,  2017,  2024,  8363,  1012,  2202,  2070,  2051,  2000,\n",
       "           9483,  4426,  1999,  1996,  3971,  2066,  2635,  1037,  3328,  1999,\n",
       "           1037,  2380,  1010,  2183,  2000,  1037,  4164,  2030,  1037,  2688,\n",
       "           1012,  1048,  4339,  1012,  2562,  1037,  9708,  1012,  4339,  2091,\n",
       "           2115,  3980,  1998,  4784,  1012,  4339,  2091,  2047,  4784,  2044,\n",
       "           2017,  3191,  1012,  1048,  3745,  1012, 15313,  2109,  2000,  2831,\n",
       "           2000,  2010,  2814,  1998,  4863,  2010,  4784,  1012,  2823,  1010,\n",
       "           1037,  2767,  2064,  2393,  2017,  2424,  1996,  3437,  2000,  1037,\n",
       "           3291,  1012,  1048,  2022,  9191,  1012,  2079,  2025,  2292,  2060,\n",
       "           2111,  2360,  2115,  4784,  2024, 10021,  1012,  4863,  4426,  1012,\n",
       "           2292,  2060,  2111,  4863,  2339,  2027,  2228,  2017,  2024,  3308,\n",
       "           1012,  2059,  5630,  1012,  1996,  3166,  4081,  2057,  2323,  6848,\n",
       "           1996,  4784,  2007,  2500,  2065,  2060,  2111,  2360,  2256,  4784,\n",
       "           2024, 10021,  1012]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, 6848, 1996, 4784, 2007, 2500,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_dataset[3679]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'discuss the ideas with others'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([6848, 1996, 4784, 2007, 2500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([1013])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
