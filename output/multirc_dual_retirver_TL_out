Model initialized
Train dataset loaded, with length 13574
Validation dataset loaded, with length 1310
Scheduler initialized
Optimizer initialized
Starting training
Evaluating zero-shot performance...
    Evaluating on 328 batches...
    Zero-shot performance loss on eval: 1.3364078020904122
    Zero-shot performance eval: 0.5641025641025641
    Zero-shot performance on train: 0.543859649122807
Training on 3394 batches
[EVAL] Timestamp: 26.01.2025 21:33:19, Epoch: 1 / 5
    Evaluating on 328 batches...
    Batch: 0 / 3394, Batch Loss: 2.1574506759643555, Eval loss: 1.2400970887847063
[LOG] Timestamp: 26.01.2025 21:34:55, Epoch: 1 / 5
    Batch: 200 / 3394, Batch Loss: 1.107104778289795
[LOG] Timestamp: 26.01.2025 21:35:59, Epoch: 1 / 5
    Batch: 400 / 3394, Batch Loss: 0.26294517517089844
[LOG] Timestamp: 26.01.2025 21:37:03, Epoch: 1 / 5
    Batch: 600 / 3394, Batch Loss: 0.6997647285461426
[LOG] Timestamp: 26.01.2025 21:38:08, Epoch: 1 / 5
    Batch: 800 / 3394, Batch Loss: 1.5749530792236328
[EVAL] Timestamp: 26.01.2025 21:39:12, Epoch: 1 / 5
    Evaluating on 328 batches...
    Batch: 1000 / 3394, Batch Loss: 0.317230224609375, Eval loss: 0.5534004380063313
[LOG] Timestamp: 26.01.2025 21:40:47, Epoch: 1 / 5
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:41:51, Epoch: 1 / 5
    Batch: 1400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:42:55, Epoch: 1 / 5
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:43:59, Epoch: 1 / 5
    Batch: 1800 / 3394, Batch Loss: 0.15114068984985352
[EVAL] Timestamp: 26.01.2025 21:45:03, Epoch: 1 / 5
    Evaluating on 328 batches...
    Batch: 2000 / 3394, Batch Loss: 0.6449456214904785, Eval loss: 0.5749467109761587
[LOG] Timestamp: 26.01.2025 21:46:39, Epoch: 1 / 5
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:47:43, Epoch: 1 / 5
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:48:47, Epoch: 1 / 5
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:49:51, Epoch: 1 / 5
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 21:50:55, Epoch: 1 / 5
    Evaluating on 328 batches...
    Batch: 3000 / 3394, Batch Loss: 0.0, Eval loss: 0.5789232741041881
[LOG] Timestamp: 26.01.2025 21:52:31, Epoch: 1 / 5
    Batch: 3200 / 3394, Batch Loss: 0.14516925811767578
[SAVE] Timestamp: 26.01.2025 21:53:33, Epoch: 1 / 5
[EPOCH EVAL] Timestamp: 26.01.2025 21:53:34 Epoch: 1 / 5
    Evaluating on 328 batches...
    Eval results: 0.8974358974358975, Eval loss: 0.6463579266536527
    Eval results on train dataset: 0.9890350877192983
[EVAL] Timestamp: 26.01.2025 21:55:24, Epoch: 2 / 5
    Evaluating on 328 batches...
    Batch: 0 / 3394, Batch Loss: 0.0, Eval loss: 0.6463405642567611
[LOG] Timestamp: 26.01.2025 21:57:00, Epoch: 2 / 5
    Batch: 200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:58:04, Epoch: 2 / 5
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 21:59:08, Epoch: 2 / 5
    Batch: 600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:00:11, Epoch: 2 / 5
    Batch: 800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:01:15, Epoch: 2 / 5
    Evaluating on 328 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.6642169240044384
[LOG] Timestamp: 26.01.2025 22:02:51, Epoch: 2 / 5
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:03:55, Epoch: 2 / 5
    Batch: 1400 / 3394, Batch Loss: 0.2999434471130371
[LOG] Timestamp: 26.01.2025 22:04:59, Epoch: 2 / 5
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:06:03, Epoch: 2 / 5
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:07:07, Epoch: 2 / 5
    Evaluating on 328 batches...
    Batch: 2000 / 3394, Batch Loss: 0.0, Eval loss: 0.5746904691544975
[LOG] Timestamp: 26.01.2025 22:08:43, Epoch: 2 / 5
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:09:47, Epoch: 2 / 5
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:10:51, Epoch: 2 / 5
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:11:55, Epoch: 2 / 5
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:12:59, Epoch: 2 / 5
    Evaluating on 328 batches...
    Batch: 3000 / 3394, Batch Loss: 0.0, Eval loss: 0.7185959786903567
[LOG] Timestamp: 26.01.2025 22:14:35, Epoch: 2 / 5
    Batch: 3200 / 3394, Batch Loss: 0.5048789978027344
[SAVE] Timestamp: 26.01.2025 22:15:37, Epoch: 2 / 5
[EPOCH EVAL] Timestamp: 26.01.2025 22:15:38 Epoch: 2 / 5
    Evaluating on 328 batches...
    Eval results: 0.8717948717948718, Eval loss: 0.6009967610603426
    Eval results on train dataset: 0.9912280701754386
[EVAL] Timestamp: 26.01.2025 22:17:27, Epoch: 3 / 5
    Evaluating on 328 batches...
    Batch: 0 / 3394, Batch Loss: 0.0, Eval loss: 0.6006911396980286
[LOG] Timestamp: 26.01.2025 22:19:03, Epoch: 3 / 5
    Batch: 200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:20:07, Epoch: 3 / 5
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:21:11, Epoch: 3 / 5
    Batch: 600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:22:15, Epoch: 3 / 5
    Batch: 800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:23:19, Epoch: 3 / 5
    Evaluating on 328 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.6049829379814428
[LOG] Timestamp: 26.01.2025 22:24:55, Epoch: 3 / 5
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:25:59, Epoch: 3 / 5
    Batch: 1400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:27:03, Epoch: 3 / 5
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:28:07, Epoch: 3 / 5
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:29:11, Epoch: 3 / 5
    Evaluating on 328 batches...
    Batch: 2000 / 3394, Batch Loss: 0.0, Eval loss: 0.5988937005764101
[LOG] Timestamp: 26.01.2025 22:30:47, Epoch: 3 / 5
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:31:51, Epoch: 3 / 5
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:32:55, Epoch: 3 / 5
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:33:59, Epoch: 3 / 5
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:35:03, Epoch: 3 / 5
    Evaluating on 328 batches...
    Batch: 3000 / 3394, Batch Loss: 0.0, Eval loss: 0.6402275111617112
[LOG] Timestamp: 26.01.2025 22:36:39, Epoch: 3 / 5
    Batch: 3200 / 3394, Batch Loss: 0.0
[SAVE] Timestamp: 26.01.2025 22:37:40, Epoch: 3 / 5
[EPOCH EVAL] Timestamp: 26.01.2025 22:37:42 Epoch: 3 / 5
    Evaluating on 328 batches...
    Eval results: 0.9230769230769231, Eval loss: 0.6345237188222932
    Eval results on train dataset: 0.9912280701754386
[EVAL] Timestamp: 26.01.2025 22:39:31, Epoch: 4 / 5
    Evaluating on 328 batches...
    Batch: 0 / 3394, Batch Loss: 0.0, Eval loss: 0.635488153957739
[LOG] Timestamp: 26.01.2025 22:41:07, Epoch: 4 / 5
    Batch: 200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:42:11, Epoch: 4 / 5
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:43:15, Epoch: 4 / 5
    Batch: 600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:44:19, Epoch: 4 / 5
    Batch: 800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:45:23, Epoch: 4 / 5
    Evaluating on 328 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.6407624933777786
[LOG] Timestamp: 26.01.2025 22:46:59, Epoch: 4 / 5
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:48:03, Epoch: 4 / 5
    Batch: 1400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:49:06, Epoch: 4 / 5
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:50:10, Epoch: 4 / 5
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:51:14, Epoch: 4 / 5
    Evaluating on 328 batches...
    Batch: 2000 / 3394, Batch Loss: 0.0, Eval loss: 0.64579911057542
[LOG] Timestamp: 26.01.2025 22:52:50, Epoch: 4 / 5
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:53:54, Epoch: 4 / 5
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:54:58, Epoch: 4 / 5
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 22:56:02, Epoch: 4 / 5
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 22:57:06, Epoch: 4 / 5
    Evaluating on 328 batches...
    Batch: 3000 / 3394, Batch Loss: 0.0, Eval loss: 0.6342314743414158
[LOG] Timestamp: 26.01.2025 22:58:42, Epoch: 4 / 5
    Batch: 3200 / 3394, Batch Loss: 0.0
[SAVE] Timestamp: 26.01.2025 22:59:44, Epoch: 4 / 5
[EPOCH EVAL] Timestamp: 26.01.2025 22:59:45 Epoch: 4 / 5
    Evaluating on 328 batches...
    Eval results: 0.8461538461538461, Eval loss: 0.6482723093614345
    Eval results on train dataset: 0.9912280701754386
[EVAL] Timestamp: 26.01.2025 23:01:35, Epoch: 5 / 5
    Evaluating on 328 batches...
    Batch: 0 / 3394, Batch Loss: 0.0, Eval loss: 0.6478320505560898
[LOG] Timestamp: 26.01.2025 23:03:10, Epoch: 5 / 5
    Batch: 200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:04:14, Epoch: 5 / 5
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:05:18, Epoch: 5 / 5
    Batch: 600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:06:22, Epoch: 5 / 5
    Batch: 800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 23:07:26, Epoch: 5 / 5
    Evaluating on 328 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.6290876458330852
[LOG] Timestamp: 26.01.2025 23:09:02, Epoch: 5 / 5
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:10:06, Epoch: 5 / 5
    Batch: 1400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:11:10, Epoch: 5 / 5
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:12:14, Epoch: 5 / 5
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 23:13:18, Epoch: 5 / 5
    Evaluating on 328 batches...
    Batch: 2000 / 3394, Batch Loss: 0.0, Eval loss: 0.618783843953435
[LOG] Timestamp: 26.01.2025 23:14:54, Epoch: 5 / 5
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:15:58, Epoch: 5 / 5
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:17:02, Epoch: 5 / 5
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 26.01.2025 23:18:06, Epoch: 5 / 5
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 26.01.2025 23:19:10, Epoch: 5 / 5
    Evaluating on 328 batches...
    Batch: 3000 / 3394, Batch Loss: 0.0, Eval loss: 0.6198833657474052
[LOG] Timestamp: 26.01.2025 23:20:46, Epoch: 5 / 5
    Batch: 3200 / 3394, Batch Loss: 0.0
[SAVE] Timestamp: 26.01.2025 23:21:47, Epoch: 5 / 5
[EPOCH EVAL] Timestamp: 26.01.2025 23:21:49 Epoch: 5 / 5
    Evaluating on 328 batches...
    Eval results: 0.8974358974358975, Eval loss: 0.6536873826166478
    Eval results on train dataset: 0.9912280701754386
Training finished
Saving model...
Model saved