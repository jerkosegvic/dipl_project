Model initialized
Train dataset loaded, with length 9427
Validation dataset loaded, with length 3269
Optimizer initialized
Starting training
Evaluating zero-shot performance...
    Zero-shot performance: 0.4371367390639339
Training on 2357 batches
[EVAL] Timestamp: 29.12.2024 11:47:12, Epoch: 1 / 5
    Evaluating on 818 batches...
    Batch: 0 / 2357, Batch Loss: 8.460596084594727, Eval loss: 2.3074407288964047
[LOG] Timestamp: 29.12.2024 12:00:47, Epoch: 1 / 5
    Batch: 200 / 2357, Batch Loss: 6.364542059600353e-05
[LOG] Timestamp: 29.12.2024 12:09:05, Epoch: 1 / 5
    Batch: 400 / 2357, Batch Loss: 0.00013906939420849085
[LOG] Timestamp: 29.12.2024 12:17:25, Epoch: 1 / 5
    Batch: 600 / 2357, Batch Loss: 2.3647406123927794e-05
[LOG] Timestamp: 29.12.2024 12:25:46, Epoch: 1 / 5
    Batch: 800 / 2357, Batch Loss: 6.988573204580462e-06
[EVAL] Timestamp: 29.12.2024 12:34:07, Epoch: 1 / 5
    Evaluating on 818 batches...
    Batch: 1000 / 2357, Batch Loss: 1.0117813872057013e-05, Eval loss: 1.3613518191463999e-05
[LOG] Timestamp: 29.12.2024 12:47:46, Epoch: 1 / 5
    Batch: 1200 / 2357, Batch Loss: 7.018378710199613e-06
[LOG] Timestamp: 29.12.2024 12:56:06, Epoch: 1 / 5
    Batch: 1400 / 2357, Batch Loss: 1.5795014405739494e-05
[LOG] Timestamp: 29.12.2024 13:04:28, Epoch: 1 / 5
    Batch: 1600 / 2357, Batch Loss: 2.6076972972077783e-06
[LOG] Timestamp: 29.12.2024 13:12:50, Epoch: 1 / 5
    Batch: 1800 / 2357, Batch Loss: 7.569734862045152e-06
[EVAL] Timestamp: 29.12.2024 13:21:13, Epoch: 1 / 5
    Evaluating on 818 batches...
    Batch: 2000 / 2357, Batch Loss: 2.518199289625045e-05, Eval loss: 7.235767397784305e-06
[LOG] Timestamp: 29.12.2024 13:34:53, Epoch: 1 / 5
    Batch: 2200 / 2357, Batch Loss: 9.238710276804341e-07
[EPOCH EVAL] Timestamp: 29.12.2024 13:41:24) Epoch: 1 / 5
    Evaluating on 818 batches...
    Eval results: 0.485469562557357, Eval loss: 2.6936482649917677e-06
[EVAL] Timestamp: 29.12.2024 13:58:27, Epoch: 2 / 5
    Evaluating on 818 batches...
    Batch: 0 / 2357, Batch Loss: 7.301563300643465e-07, Eval loss: 2.672678197524984e-06
[LOG] Timestamp: 29.12.2024 14:12:06, Epoch: 2 / 5
    Batch: 200 / 2357, Batch Loss: 1.5646168094463064e-06
[LOG] Timestamp: 29.12.2024 14:20:29, Epoch: 2 / 5
    Batch: 400 / 2357, Batch Loss: 1.2069407603121363e-05
[LOG] Timestamp: 29.12.2024 14:28:54, Epoch: 2 / 5
    Batch: 600 / 2357, Batch Loss: 8.672229341755155e-06
[LOG] Timestamp: 29.12.2024 14:37:19, Epoch: 2 / 5
    Batch: 800 / 2357, Batch Loss: 3.606042582759983e-06
[EVAL] Timestamp: 29.12.2024 14:45:43, Epoch: 2 / 5
    Evaluating on 818 batches...
    Batch: 1000 / 2357, Batch Loss: 1.3410989367912407e-06, Eval loss: 4.348824638486793e-06
[LOG] Timestamp: 29.12.2024 14:59:23, Epoch: 2 / 5
    Batch: 1200 / 2357, Batch Loss: 4.723628080682829e-06
[LOG] Timestamp: 29.12.2024 15:07:45, Epoch: 2 / 5
    Batch: 1400 / 2357, Batch Loss: 7.956967237987556e-06
[LOG] Timestamp: 29.12.2024 15:16:11, Epoch: 2 / 5
    Batch: 1600 / 2357, Batch Loss: 5.9604641222676946e-08
[LOG] Timestamp: 29.12.2024 15:24:36, Epoch: 2 / 5
    Batch: 1800 / 2357, Batch Loss: 1.1622857982729329e-06
[EVAL] Timestamp: 29.12.2024 15:33:01, Epoch: 2 / 5
    Evaluating on 818 batches...
    Batch: 2000 / 2357, Batch Loss: 2.3841846541472478e-07, Eval loss: 1.2761514555519175e-06
[LOG] Timestamp: 29.12.2024 15:46:41, Epoch: 2 / 5
    Batch: 2200 / 2357, Batch Loss: 8.493639711559808e-07
[EPOCH EVAL] Timestamp: 29.12.2024 15:53:13) Epoch: 2 / 5
    Evaluating on 818 batches...
    Eval results: 0.30223309880697463, Eval loss: 9.995167263004665e-07
[EVAL] Timestamp: 29.12.2024 16:10:16, Epoch: 3 / 5
    Evaluating on 818 batches...
    Batch: 0 / 2357, Batch Loss: 2.533195697651536e-07, Eval loss: 4.423838392256668e-07
[LOG] Timestamp: 29.12.2024 16:23:56, Epoch: 3 / 5
    Batch: 200 / 2357, Batch Loss: 7.450579886381092e-08
[LOG] Timestamp: 29.12.2024 16:32:19, Epoch: 3 / 5
    Batch: 400 / 2357, Batch Loss: 1.4901158351676713e-07
[LOG] Timestamp: 29.12.2024 16:40:45, Epoch: 3 / 5
    Batch: 600 / 2357, Batch Loss: 5.215400165070605e-07
[LOG] Timestamp: 29.12.2024 16:49:10, Epoch: 3 / 5
    Batch: 800 / 2357, Batch Loss: 1.9371502446574596e-07
[EVAL] Timestamp: 29.12.2024 16:57:36, Epoch: 3 / 5
    Evaluating on 818 batches...
    Batch: 1000 / 2357, Batch Loss: 0.0, Eval loss: 2.0792250570992627e-07
[LOG] Timestamp: 29.12.2024 17:11:15, Epoch: 3 / 5
    Batch: 1200 / 2357, Batch Loss: 1.4901160305669237e-08
[LOG] Timestamp: 29.12.2024 17:19:38, Epoch: 3 / 5
    Batch: 1400 / 2357, Batch Loss: 1.3411039390121005e-07
[LOG] Timestamp: 29.12.2024 17:28:04, Epoch: 3 / 5
    Batch: 1600 / 2357, Batch Loss: 1.0430809993522416e-07
[LOG] Timestamp: 29.12.2024 17:36:29, Epoch: 3 / 5
    Batch: 1800 / 2357, Batch Loss: 1.4901160305669237e-08
[EVAL] Timestamp: 29.12.2024 17:44:54, Epoch: 3 / 5
    Evaluating on 818 batches...
    Batch: 2000 / 2357, Batch Loss: 1.4901160305669237e-08, Eval loss: 1.7198038529391154e-07
[LOG] Timestamp: 29.12.2024 17:58:33, Epoch: 3 / 5
    Batch: 2200 / 2357, Batch Loss: 0.0
[EPOCH EVAL] Timestamp: 29.12.2024 18:05:04) Epoch: 3 / 5
    Evaluating on 818 batches...
    Eval results: 0.18843683083511778, Eval loss: 1.2695496973930307e-07
[EVAL] Timestamp: 29.12.2024 18:22:07, Epoch: 4 / 5
    Evaluating on 818 batches...
    Batch: 0 / 2357, Batch Loss: 1.4901160305669237e-08, Eval loss: 4.8802034197524795e-08
[LOG] Timestamp: 29.12.2024 18:35:48, Epoch: 4 / 5
    Batch: 200 / 2357, Batch Loss: 1.1920926112907182e-07
[LOG] Timestamp: 29.12.2024 18:44:10, Epoch: 4 / 5
    Batch: 400 / 2357, Batch Loss: 1.4901160305669237e-08
[LOG] Timestamp: 29.12.2024 18:52:35, Epoch: 4 / 5
    Batch: 600 / 2357, Batch Loss: 0.0005731109995394945
[LOG] Timestamp: 29.12.2024 19:00:59, Epoch: 4 / 5
    Batch: 800 / 2357, Batch Loss: 0.00017088715685531497
[EVAL] Timestamp: 29.12.2024 19:09:23, Epoch: 4 / 5
    Evaluating on 818 batches...
    Batch: 1000 / 2357, Batch Loss: 0.00011616802657954395, Eval loss: 0.0001019378630872426
[LOG] Timestamp: 29.12.2024 19:23:02, Epoch: 4 / 5
    Batch: 1200 / 2357, Batch Loss: 5.861659883521497e-05
[LOG] Timestamp: 29.12.2024 19:31:23, Epoch: 4 / 5
    Batch: 1400 / 2357, Batch Loss: 4.0886676288209856e-05
[LOG] Timestamp: 29.12.2024 19:39:47, Epoch: 4 / 5
    Batch: 1600 / 2357, Batch Loss: 3.260215453337878e-05
[LOG] Timestamp: 29.12.2024 19:48:10, Epoch: 4 / 5
    Batch: 1800 / 2357, Batch Loss: 3.111203477601521e-05
[EVAL] Timestamp: 29.12.2024 19:56:34, Epoch: 4 / 5
    Evaluating on 818 batches...
    Batch: 2000 / 2357, Batch Loss: 2.0488378140726127e-05, Eval loss: 2.4881358018310695e-05
[LOG] Timestamp: 29.12.2024 20:10:12, Epoch: 4 / 5
    Batch: 2200 / 2357, Batch Loss: 1.9341150618856773e-05
[EPOCH EVAL] Timestamp: 29.12.2024 20:16:43) Epoch: 4 / 5
    Evaluating on 818 batches...
    Eval results: 0.6124197002141327, Eval loss: 1.5362835685001657e-05
[EVAL] Timestamp: 29.12.2024 20:33:46, Epoch: 5 / 5
    Evaluating on 818 batches...
    Batch: 0 / 2357, Batch Loss: 1.1235333658987656e-05, Eval loss: 1.5267570687481116e-05
[LOG] Timestamp: 29.12.2024 20:47:25, Epoch: 5 / 5
    Batch: 200 / 2357, Batch Loss: 1.4513440873997752e-05
[LOG] Timestamp: 29.12.2024 20:55:47, Epoch: 5 / 5
    Batch: 400 / 2357, Batch Loss: 8.433960829279386e-06
[LOG] Timestamp: 29.12.2024 21:04:11, Epoch: 5 / 5
    Batch: 600 / 2357, Batch Loss: 8.150845133059192e-06
[LOG] Timestamp: 29.12.2024 21:12:35, Epoch: 5 / 5
    Batch: 800 / 2357, Batch Loss: 8.359447747352533e-06
[EVAL] Timestamp: 29.12.2024 21:20:58, Epoch: 5 / 5
    Evaluating on 818 batches...
    Batch: 1000 / 2357, Batch Loss: 7.063064913381822e-06, Eval loss: 7.910864247474588e-06
[LOG] Timestamp: 29.12.2024 21:34:37, Epoch: 5 / 5
    Batch: 1200 / 2357, Batch Loss: 6.377651516231708e-06
[LOG] Timestamp: 29.12.2024 21:42:58, Epoch: 5 / 5
    Batch: 1400 / 2357, Batch Loss: 7.539924808952492e-06
[LOG] Timestamp: 29.12.2024 21:51:22, Epoch: 5 / 5
    Batch: 1600 / 2357, Batch Loss: 4.0083846215566155e-06
[LOG] Timestamp: 29.12.2024 21:59:45, Epoch: 5 / 5
    Batch: 1800 / 2357, Batch Loss: 1.6093224530777661e-06
[EVAL] Timestamp: 29.12.2024 22:08:07, Epoch: 5 / 5
    Evaluating on 818 batches...
    Batch: 2000 / 2357, Batch Loss: 3.874279627780197e-06, Eval loss: 3.0748320855954303e-06
[LOG] Timestamp: 29.12.2024 22:21:46, Epoch: 5 / 5
    Batch: 2200 / 2357, Batch Loss: 2.6821985557035077e-06
[EPOCH EVAL] Timestamp: 29.12.2024 22:28:17) Epoch: 5 / 5
    Evaluating on 818 batches...
    Eval results: 0.6105842765371673, Eval loss: 2.385505334058238e-06
Training finished
Saving model