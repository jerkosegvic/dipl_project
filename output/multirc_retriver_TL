Model initialized
Train dataset loaded, with length 13574
Validation dataset loaded, with length 2432
Scheduler initialized
Optimizer initialized
Starting training
Evaluating zero-shot performance...
    Evaluating on 608 batches...
    Zero-shot performance loss on eval: 1.410479431481738
    Zero-shot performance eval: 0.4268292682926829
    Zero-shot performance on train: 0.5482456140350878
Training on 3394 batches
[EVAL] Timestamp: 14.01.2025 13:13:07, Epoch: 1 / 3
    Evaluating on 608 batches...
    Batch: 0 / 3394, Batch Loss: 2.268141031265259, Eval loss: 1.3970240411397659
[LOG] Timestamp: 14.01.2025 13:15:07, Epoch: 1 / 3
    Batch: 200 / 3394, Batch Loss: 1.072188377380371
[LOG] Timestamp: 14.01.2025 13:16:09, Epoch: 1 / 3
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:17:11, Epoch: 1 / 3
    Batch: 600 / 3394, Batch Loss: 0.3402090072631836
[LOG] Timestamp: 14.01.2025 13:18:13, Epoch: 1 / 3
    Batch: 800 / 3394, Batch Loss: 0.7780168056488037
[EVAL] Timestamp: 14.01.2025 13:19:15, Epoch: 1 / 3
    Evaluating on 608 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.45445019320437785
[LOG] Timestamp: 14.01.2025 13:21:16, Epoch: 1 / 3
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:22:18, Epoch: 1 / 3
    Batch: 1400 / 3394, Batch Loss: 0.14571619033813477
[LOG] Timestamp: 14.01.2025 13:23:20, Epoch: 1 / 3
    Batch: 1600 / 3394, Batch Loss: 0.14946818351745605
[LOG] Timestamp: 14.01.2025 13:24:22, Epoch: 1 / 3
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 14.01.2025 13:25:24, Epoch: 1 / 3
    Evaluating on 608 batches...
    Batch: 2000 / 3394, Batch Loss: 0.0, Eval loss: 0.5123451132523386
[LOG] Timestamp: 14.01.2025 13:27:25, Epoch: 1 / 3
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:28:27, Epoch: 1 / 3
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:29:29, Epoch: 1 / 3
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:30:31, Epoch: 1 / 3
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 14.01.2025 13:31:33, Epoch: 1 / 3
    Evaluating on 608 batches...
    Batch: 3000 / 3394, Batch Loss: 0.24036693572998047, Eval loss: 0.5377707140226113
[LOG] Timestamp: 14.01.2025 13:33:34, Epoch: 1 / 3
    Batch: 3200 / 3394, Batch Loss: 0.0
[EPOCH EVAL] Timestamp: 14.01.2025 13:34:34) Epoch: 1 / 3
    Evaluating on 608 batches...
    Eval results: 0.8902439024390244, Eval loss: 0.5213445660315061
    Eval results on train dataset: 0.9912280701754386
[EVAL] Timestamp: 14.01.2025 13:36:57, Epoch: 2 / 3
    Evaluating on 608 batches...
    Batch: 0 / 3394, Batch Loss: 0.0, Eval loss: 0.5214168092137889
[LOG] Timestamp: 14.01.2025 13:38:58, Epoch: 2 / 3
    Batch: 200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:40:00, Epoch: 2 / 3
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:41:02, Epoch: 2 / 3
    Batch: 600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:42:04, Epoch: 2 / 3
    Batch: 800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 14.01.2025 13:43:06, Epoch: 2 / 3
    Evaluating on 608 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.5279852049915414
[LOG] Timestamp: 14.01.2025 13:45:07, Epoch: 2 / 3
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:46:09, Epoch: 2 / 3
    Batch: 1400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:47:11, Epoch: 2 / 3
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:48:13, Epoch: 2 / 3
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 14.01.2025 13:49:15, Epoch: 2 / 3
    Evaluating on 608 batches...
    Batch: 2000 / 3394, Batch Loss: 0.0, Eval loss: 0.5497903506222525
[LOG] Timestamp: 14.01.2025 13:51:16, Epoch: 2 / 3
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 13:52:18, Epoch: 2 / 3
    Batch: 2400 / 3394, Batch Loss: 0.16375303268432617
[LOG] Timestamp: 14.01.2025 13:53:20, Epoch: 2 / 3
    Batch: 2600 / 3394, Batch Loss: 0.3730659484863281
[LOG] Timestamp: 14.01.2025 13:54:22, Epoch: 2 / 3
    Batch: 2800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 14.01.2025 13:55:24, Epoch: 2 / 3
    Evaluating on 608 batches...
    Batch: 3000 / 3394, Batch Loss: 0.11306142807006836, Eval loss: 0.5306464774828208
[LOG] Timestamp: 14.01.2025 13:57:26, Epoch: 2 / 3
    Batch: 3200 / 3394, Batch Loss: 0.0
[EPOCH EVAL] Timestamp: 14.01.2025 13:58:25) Epoch: 2 / 3
    Evaluating on 608 batches...
    Eval results: 0.9146341463414634, Eval loss: 0.5453078880121833
    Eval results on train dataset: 0.9912280701754386
[EVAL] Timestamp: 14.01.2025 14:00:48, Epoch: 3 / 3
    Evaluating on 608 batches...
    Batch: 0 / 3394, Batch Loss: 0.0, Eval loss: 0.5456163287162781
[LOG] Timestamp: 14.01.2025 14:02:50, Epoch: 3 / 3
    Batch: 200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:03:52, Epoch: 3 / 3
    Batch: 400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:04:54, Epoch: 3 / 3
    Batch: 600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:05:56, Epoch: 3 / 3
    Batch: 800 / 3394, Batch Loss: 0.8726396560668945
[EVAL] Timestamp: 14.01.2025 14:06:58, Epoch: 3 / 3
    Evaluating on 608 batches...
    Batch: 1000 / 3394, Batch Loss: 0.0, Eval loss: 0.5687135175654763
[LOG] Timestamp: 14.01.2025 14:08:59, Epoch: 3 / 3
    Batch: 1200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:10:01, Epoch: 3 / 3
    Batch: 1400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:11:03, Epoch: 3 / 3
    Batch: 1600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:12:05, Epoch: 3 / 3
    Batch: 1800 / 3394, Batch Loss: 0.0
[EVAL] Timestamp: 14.01.2025 14:13:07, Epoch: 3 / 3
    Evaluating on 608 batches...
    Batch: 2000 / 3394, Batch Loss: 0.05355215072631836, Eval loss: 0.537145663641001
[LOG] Timestamp: 14.01.2025 14:15:08, Epoch: 3 / 3
    Batch: 2200 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:16:10, Epoch: 3 / 3
    Batch: 2400 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:17:12, Epoch: 3 / 3
    Batch: 2600 / 3394, Batch Loss: 0.0
[LOG] Timestamp: 14.01.2025 14:18:14, Epoch: 3 / 3
    Batch: 2800 / 3394, Batch Loss: 0.25739288330078125
[EVAL] Timestamp: 14.01.2025 14:19:16, Epoch: 3 / 3
    Evaluating on 608 batches...
    Batch: 3000 / 3394, Batch Loss: 0.0, Eval loss: 0.5184712649175995
[LOG] Timestamp: 14.01.2025 14:21:17, Epoch: 3 / 3
    Batch: 3200 / 3394, Batch Loss: 0.0
[EPOCH EVAL] Timestamp: 14.01.2025 14:22:16) Epoch: 3 / 3
    Evaluating on 608 batches...
    Eval results: 0.8780487804878049, Eval loss: 0.5301534368803626
    Eval results on train dataset: 0.9890350877192983
Training complete
Model saved
